# This configuration corresponds to Ours (Mono-SC Train.) in the extended paper.
# NOTE: the predicted trajectory is not in the real-world scale.

#-------------------------------------
#- Basic setup
#-------------------------------------
dataset: zed2                                            # dataset [kitti_odom, kitti_raw, tum-1/2/3, adelaide1/2, m2dgr]
seed: 4869                                                # random seed
image:
    height: 720                                           # image height
    width: 1280                                           # image width
    ext: png                                              # image file extension for data loading

#-------------------------------------
#- Directories
#-------------------------------------
directory:
    result_dir: result/tmp/4/                             # directory to save result
    flow_dir: dataset/zed2/flow_data/               # (optional) external flow data directory
    pose_dir: dataset/zed2/pose_data/               # (optional) external pose data directory
    sparse_depth_dir: dataset/zed2/sparse_depth/    # (optional) external sparse depth data directory
    img_seq_dir: dataset/zed2/odom_data/            # image data directory
    gt_pose_dir:                                          # (optional) ground-truth pose data directory
    depth_dir:                                            # (optional) external depth data, e.g. ground-truth depths

#-------------------------------------
#- Depth
#-------------------------------------
depth:                                                    # Depth configuration
    depth_src:                                            # depth source [None, gt]
    deep_depth:
        network: monodepth2
        pretrained_model: model_zoo/depth/kitti_odom/mono_sc/  # directory stores depth.pth and encoder.pth 

deep_flow:                                                # Deep optical flow configuration
    enable: True                                         # True -> DF-VO, False -> ORB-SLAM3

# ------------------------------------
# Online Learning
# ------------------------------------
online_learning:                                          # online learning configuration
    enable: False                                          # enable/disable
    val_enable: False                                      # enable/disable validation
    mode: refiner                                        # finetune, refiner or bn
    lora_r: 2 #8                                             # lora r in encoder
    lora_r2: 2 #8                                            # lora r in decoder
    batch_size: 4                                         # batch size
    max_size: 3                                           # maximum number of keyframe list
    val_step: 10                                          # validation step


#-------------------------------------
#- Visualization
#-------------------------------------
visualization:                                            # visualization configuration
    enable: True                                          # enable/disable frame drawer
    trajectory:                                           # trajectory visualization configuration
        vis_traj: True                                    # enable/disable predicted trajectory visualization
        vis_gt_traj: False                                # enable/disable ground truth trajectory visualization
        mono_scale: 1                                    # monocular prediction scaling factor
        vis_scale: 1
