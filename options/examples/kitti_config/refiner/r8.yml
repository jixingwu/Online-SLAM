# This configuration corresponds to Ours (Mono-SC Train.) in the extended paper.
# NOTE: the predicted trajectory is not in the real-world scale.

#-------------------------------------
#- Basic setup
#-------------------------------------
dataset: kitti_odom                                       # dataset [kitti_odom, kitti_raw, tum-1/2/3, adelaide1/2]
seed: 4869                                                # random seed
image:
    height: 370                                           # image height
    width: 1226                                           # image width
    ext: png                                              # image file extension for data loading

#-------------------------------------
#- Directories
#-------------------------------------
directory:
    result_dir: result/tmp/1/                             # directory to save result
    flow_dir: dataset/kitti_odom/flow_data/               # (optional) external flow data directory
    pose_dir: dataset/kitti_odom/pose_data/               # (optional) external pose data directory
    sparse_depth_dir: dataset/kitti_odom/sparse_depth/    # (optional) external sparse depth data directory
    img_seq_dir: dataset/kitti_odom/odom_data/            # image data directory
    gt_pose_dir:                                          # (optional) ground-truth pose data directory
    depth_dir:                                            # (optional) external depth data, e.g. ground-truth depths

#-------------------------------------
#- Depth
#-------------------------------------
depth:                                                    # Depth configuration
    depth_src:                                            # depth source [None, gt]
    deep_depth:
        network: sc_depthv3
        parameter_file: options/configs/v1/kitti_odom.txt
        pretrained_model: model_zoo/depth/sc_depthv3/ddad_scv3/epoch=99-val_loss=0.1438.ckpt

# ------------------------------------
# Online Learning
# ------------------------------------
online_learning:                                          # online learning configuration
    enable: True                                          # enable/disable
    val_enable: True                                      # enable/disable validation
    mode: refiner                                        # finetune, refiner or bn
    lora_r: 8                                             # lora r in encoder
    lora_r2: 8                                            # lora r in decoder
    val_enable: True                                      # enable/disable validation
    batch_size: 2                                         # batch size
    max_size: 3                                           # maximum number of keyframe list
    val_step: 10                                          # validation step


#-------------------------------------
#- Visualization
#-------------------------------------
visualization:                                            # visualization configuration
    trajectory:                                           # trajectory visualization configuration
        vis_traj: True                                    # enable/disable predicted trajectory visualization
        vis_gt_traj: False                                # enable/disable ground truth trajectory visualization
        mono_scale: 1                                    # monocular prediction scaling factor
        vis_scale: 1
